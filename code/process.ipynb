{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "use_average = True\n",
    "use_predict = True\n",
    "\n",
    "output_name = 'average.csv' if use_average else 'normal.csv'\n",
    "output_name2020 = '2020average.csv' if use_average else '2020normal.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    del df['Station Name']\n",
    "    del df['Climate ID']\n",
    "    del df['Longitude (x)']\n",
    "    del df['Latitude (y)']\n",
    "    del df['Year']\n",
    "    del df['Month']\n",
    "    del df['Day']\n",
    "    del df['Time']\n",
    "\n",
    "\n",
    "    df.columns = ['date', 'temp', 'dew', 'rel', 'wdir', 'wspeed', 'stn']\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_predict:\n",
    "    df1 = read_csv('HALIFAX DOCKYARD.csv')\n",
    "    df2 = read_csv('HALIFAX KOOTENAY.csv')\n",
    "else:\n",
    "    df1 = read_csv('2020-HALIFAX DOCKYARD.csv')\n",
    "    df2 = read_csv('2020-HALIFAX KOOTENAY.csv')\n",
    "\n",
    "if use_average:\n",
    "    data = {'date': df1['date'],\n",
    "            'temp': (df1['temp'] + df2['temp'])/2.0,\n",
    "            'dew': (df1['dew'] + df2['dew'])/2.0,\n",
    "            'rel': (df1['rel'] + df2['rel'])/2.0,\n",
    "            'wdir': (df1['wdir'] + df2['wdir'])/2.0,\n",
    "            'wspeed': (df1['wspeed'] + df2['wspeed'])/2.0,\n",
    "            'stn': (df1['stn'] + df2['stn'])/2.0,\n",
    "            }\n",
    "\n",
    "else:\n",
    "    data = {'date': df1['date'],\n",
    "            's1_temp': df1['temp'],\n",
    "            's2_temp': df2['temp'],\n",
    "            's1_dew': df1['dew'],\n",
    "            's2_dew': df2['dew'],\n",
    "            's1_rel': df1['rel'],\n",
    "            's2_rel': df2['rel'],\n",
    "            's1_wdir': df1['wdir'],\n",
    "            's2_wdir': df2['wdir'],\n",
    "            's1_wspeed': df1['wspeed'],\n",
    "            's2_wspeed': df2['wspeed'],\n",
    "            's1_stn': df1['stn'],\n",
    "            's2_stn': df2['stn'],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "def str2datetime(string):\n",
    "    return datetime.datetime.strptime(string, '%b %d, %Y %I%p')\n",
    "\n",
    "if use_predict:\n",
    "    headache = [\n",
    "    [str2datetime('Sep 5, 2019 7AM'), str2datetime('Sep 5, 2019 10AM'), 8],\n",
    "    [str2datetime('Sep 15, 2019 9AM'), str2datetime('Sep 15, 2019 3PM'), 7],\n",
    "    [str2datetime('Sep 27, 2019 3PM'), str2datetime('Sep 27, 2019 9PM'), 8],\n",
    "    [str2datetime('Oct 15, 2019 2PM'), str2datetime('OCT 15, 2019 6PM'), 7],\n",
    "    [str2datetime('Oct 16, 2019 4AM'), str2datetime('OCt 16, 2019 6PM'), 10],\n",
    "    [str2datetime('Oct 28, 2019 3PM'), str2datetime('OCT 28, 2019 9PM'), 6],\n",
    "    [str2datetime('Nov 28, 2019 5PM'), str2datetime('Nov 28, 2019 6PM'), 6],\n",
    "    [str2datetime('Dec 10, 2019 5AM'), str2datetime('Dec 10, 2019 10AM'), 4],\n",
    "    [str2datetime('Dec 15, 2019 2AM'), str2datetime('Dec 15, 2019 10AM'), 7],\n",
    "    [str2datetime('Dec 20, 2019 1PM'), str2datetime('Dec 20, 2019 6PM'), 9],\n",
    "    ]\n",
    "\n",
    "workout = [\n",
    "    [str2datetime('SEP 2, 2019 6PM'), str2datetime('SEP 2, 2019 7PM')],\n",
    "    [str2datetime('SEP 4, 2019 6PM'), str2datetime('SEP 4, 2019 7PM')],\n",
    "    [str2datetime('SEP 6, 2019 6PM'), str2datetime('SEP 6, 2019 7PM')],\n",
    "    [str2datetime('SEP 27, 2019 6PM'), str2datetime('SEP 27, 2019 7PM')],\n",
    "    [str2datetime('OCT 8, 2019 6PM'), str2datetime('OCT 8, 2019 7PM')],\n",
    "    [str2datetime('OCT 20, 2019 8PM'), str2datetime('OCT 20, 2019 9PM')],\n",
    "    [str2datetime('OCT 27, 2019 6AM'), str2datetime('OCT 27, 2019 7AM')],\n",
    "    [str2datetime('OCT 28, 2019 6PM'), str2datetime('OCT 28, 2019 7PM')],\n",
    "    [str2datetime('NOV 2, 2019 6PM'), str2datetime('NOV 2, 2019 7PM')],\n",
    "    [str2datetime('NOV 7, 2019 6PM'), str2datetime('NOV 7, 2019 7PM')],\n",
    "    [str2datetime('NOV 9, 2019 6PM'), str2datetime('NOV 9, 2019 7PM')],\n",
    "    [str2datetime('NOV 12, 2019 6PM'), str2datetime('NOV 12, 2019 7PM')],\n",
    "    [str2datetime('NOV 20, 2019 6PM'), str2datetime('NOV 20, 2019 7PM')],\n",
    "    [str2datetime('DEC 15, 2019 6PM'), str2datetime('DEC 15, 2019 7PM')],\n",
    "    [str2datetime('DEC 16, 2019 6PM'), str2datetime('DEC 16, 2019 7PM')],\n",
    "    [str2datetime('SEP 2, 2020 6PM'), str2datetime('SEP 2, 2020 7PM')],\n",
    "    [str2datetime('SEP 4, 2020 6PM'), str2datetime('SEP 4, 2020 7PM')],\n",
    "    [str2datetime('SEP 6, 2020 6PM'), str2datetime('SEP 6, 2020 7PM')],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = pd.Series([0]* df['date'].size)\n",
    "df['dayweek'] = pd.Series([0]* df['date'].size)\n",
    "for i in range(df['date'].size):\n",
    "    df['hour'][i] = df['date'][i].hour\n",
    "    df['dayweek'][i] = df['date'][i].weekday()\n",
    "\n",
    "df['workout'] = pd.Series([0]* df['date'].size)\n",
    "workout_index = []\n",
    "for w in workout:\n",
    "    for i in range(df['date'].size):\n",
    "        if w[0] <= df['date'][i] < w[1]:\n",
    "            workout_index.append(i)\n",
    "df['workout'][workout_index] = 1\n",
    "\n",
    "df['work'] = pd.Series([0]* df['date'].size)\n",
    "for i in range(df['date'].size):\n",
    "    if df['date'][i].weekday() == 6 or df['date'][i].weekday() == 0:\n",
    "        continue\n",
    "    if df['date'][i].hour < 9 or df['date'][i].hour > 17:\n",
    "        continue\n",
    "    if str2datetime('OCT 27, 2019 1AM') < df['date'][i] < str2datetime('NOV 3, 2019 11PM'):\n",
    "        continue\n",
    "    df['work'][i] = 1\n",
    "df['work_hour'] = pd.Series([0] * df['date'].size)\n",
    "work_sum = 0\n",
    "for i in range(df['date'].size):\n",
    "    if df['work'][i] == 1:\n",
    "        work_sum += 1\n",
    "        df['work_hour'][i] = work_sum\n",
    "    else:\n",
    "        work_sum = 0\n",
    "\n",
    "if use_predict:\n",
    "    df['headache'] = pd.Series([0]* df['date'].size)\n",
    "    for w in headache:\n",
    "        for i in range(df['date'].size):\n",
    "            if df['date'][i] >= w[0] and df['date'][i] < w[1]:\n",
    "                df['headache'][i] = w[2]\n",
    "\n",
    "# del df['date']\n",
    "if use_predict:\n",
    "    df.to_csv(output_name)\n",
    "else:\n",
    "    df.to_csv(output_name2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_predict and use_average:\n",
    "    data = pd.read_csv('average.csv')\n",
    "elif use_predict and not use_average:\n",
    "    data = pd.read_csv('normal.csv')\n",
    "elif not use_predict and use_average:\n",
    "    data = pd.read_csv('2020average.csv')\n",
    "else:\n",
    "    data = pd.read_csv('2020normal.csv')\n",
    "\n",
    "df = data.dropna(axis = 0 , how = 'any')\n",
    "\n",
    "checkFor_nan = df.isnull().values.any()\n",
    "print (checkFor_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_predict and use_average:\n",
    "    df.to_csv('DataSetAverage.csv')\n",
    "elif use_predict and not use_average:\n",
    "    df.to_csv('DataSetNormal.csv')\n",
    "elif not use_predict and use_average:\n",
    "    df.to_csv('PredictionDataAverage.csv')\n",
    "else:\n",
    "    df.to_csv('PredictionDataNormal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "data = pd.read_csv('DataSetAverage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Data Correlation\n",
    "alpha = data.columns\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date is deleted since it is not usefull for decision Tree\n",
    "df = data.drop(['date'], 1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = data.columns\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(data.corr())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels(['']+alpha, rotation='vertical',verticalalignment='bottom')\n",
    "ax.set_yticklabels(['']+alpha)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data with high correlation is deleted\n",
    "df = data.drop(['dew', 'work','dayweek'], 1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check and remove null record data by row.\n",
    "Rnan = []\n",
    "for index, row in df.iterrows():\n",
    "    isnanValue = row.isnull()\n",
    "    if isnanValue.any():\n",
    "        Rnan.append(index)\n",
    "\n",
    "print(Rnan)\n",
    "df = df.dropna(axis=0, how='any')\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[['temp', 'rel', 'wdir', 'wspeed', 'stn', 'hour', 'workout', 'work_hour']]\n",
    "\n",
    "y_train = df['headache']\n",
    "\n",
    "factor = compute_class_weight('balanced', list(Counter(y_train).keys()), y_train)\n",
    "class_weights = {k:v for k, v in zip(Counter(y_train).keys(), factor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "def run_cross_validation_on_trees(X, y, tree_depths, weights=None, cv=5, scoring='accuracy'):\n",
    "    Slist = []\n",
    "    Mean = []\n",
    "    InputCV = []\n",
    "    accuracy = []\n",
    "    for depth in tree_depths:\n",
    "        tree_model = DecisionTreeClassifier(max_depth=depth, class_weight=weights)\n",
    "        SC = cross_val_score(tree_model, X, y, cv=cv, scoring=scoring)\n",
    "        Mean.append(SC.mean())\n",
    "        InputCV.append(SC.std())\n",
    "        Slist.append(SC)\n",
    "        accuracy.append(tree_model.fit(X, y).score(X, y))\n",
    "    Mean = np.array(Mean)\n",
    "    InputCV = np.array(InputCV)\n",
    "    accuracy = np.array(accuracy)\n",
    "    return Mean, InputCV, accuracy\n",
    "\n",
    "def plot_cross_validation_on_trees(depths, cv_scores_mean, cv_scores_std, accuracy_scores, title):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15,5))\n",
    "    ax.plot(depths, cv_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)\n",
    "    ax.fill_between(depths, cv_scores_mean-cv_scores_std, cv_scores_mean+cv_scores_std, alpha=0.2)\n",
    "    ylim = plt.ylim()\n",
    "    ax.plot(depths, accuracy_scores, '-*', label='train accuracy', alpha=0.9)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Tree depth', fontsize=14)\n",
    "    ax.set_ylabel('Accuracy', fontsize=14)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xticks(depths)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting trees of depth 1 to 10 - unbalanced data\n",
    "sm_tree_depths = range(1,10)\n",
    "sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores = run_cross_validation_on_trees(X_train, y_tra\n",
    "in, sm_tree_depths)\n",
    "\n",
    "# plotting accuracy\n",
    "plot_cross_validation_on_trees(sm_tree_depths, sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores\n",
    ",\n",
    " 'Accuracy per decision tree depth on training data-Unweighted classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # fitting trees of depth 1 to 10 - weighted data\n",
    "sm_tree_depths = range(1,10)\n",
    "sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores = run_cross_validation_on_trees(X_train, y_tra\n",
    "in, sm_tree_depths, class_weights)\n",
    "\n",
    "# plotting accuracy\n",
    "plot_cross_validation_on_trees(sm_tree_depths, sm_cv_scores_mean, sm_cv_scores_std, sm_accuracy_scores\n",
    ",\n",
    " 'Accuracy per decision tree depth on training data - weighted labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_max = sm_cv_scores_mean.argmax()\n",
    "sm_best_tree_depth = sm_tree_depths[idx_max]\n",
    "sm_best_tree_cv_score = sm_cv_scores_mean[idx_max]\n",
    "sm_best_tree_cv_score_std = sm_cv_scores_std[idx_max]\n",
    "print('The depth-{} tree achieves the best mean cross-validation accuracy {} +/- {}% on training dataset'.format(\n",
    "    sm_best_tree_depth, round(sm_best_tree_cv_score*100,5), round(sm_best_tree_cv_score_std*100, 5\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training and evaluating a tree\n",
    "def run_single_tree(X_train, y_train, depth):\n",
    "    model = DecisionTreeClassifier(max_depth=depth).fit(X_train, y_train)\n",
    "    fig, axes = plt.subplots(nrows = 1,ncols = 1, figsize=(10,5), dpi=100)\n",
    "    tree.plot_tree(model, feature_names = X_train.columns, filled = True)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = run_single_tree(X_train, y_train, sm_best_tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train.columns[np.argsort(model.feature_importances_)[::-1]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('2020average.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_data.drop(['date', 'dew', 'work','dayweek'], 1)\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = []\n",
    "for index, row in test_df.iterrows():\n",
    "    is_nan_series = row.isnull()\n",
    "    if is_nan_series.any():\n",
    "        rows_with_nan.append(index)\n",
    "        \n",
    "print(rows_with_nan)\n",
    "test_df = test_df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(model.predict_proba(test_df)[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict_proba(test_df)\n",
    "count=0\n",
    "for x in a:\n",
    "    count+=1\n",
    "    if sum(x[1:])> .5 :\n",
    "        print(sum(x[1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
